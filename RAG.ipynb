{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sdtfe-Rz0z7Y"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Embeddings"
      ],
      "metadata": {
        "id": "_dvzWTDWEkzZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from embeddings.base import BaseEmbedding, APIBaseEmbedding, EmbeddingConfig\n",
        "from embeddings.sentenceTransformer import SentenceTransformerEmbedding\n",
        "from embeddings.openai import OpenAIEmbedding\n",
        "from embeddings.google import GoogleEmbedding"
      ],
      "metadata": {
        "id": "QUzSL_c5EcG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic.v1 import BaseModel, Field, validator\n",
        "from typing import Any, Optional\n",
        "\n",
        "class EmbeddingConfig(BaseModel):\n",
        "    name: str = Field(..., description=\"The name of the SentenceTransformer model\")\n",
        "\n",
        "    @validator('name')\n",
        "    def check_model_name(cls, value):\n",
        "        if not isinstance(value, str) or not value.strip():\n",
        "            raise ValueError(\"Model name must be a non-empty string\")\n",
        "        return value\n",
        "\n",
        "class BaseEmbedding():\n",
        "    name: str\n",
        "\n",
        "    def __init__(self, name: str):\n",
        "        super().__init__()\n",
        "        self.name = name\n",
        "\n",
        "    def encode(self, text: str):\n",
        "        raise NotImplementedError(\"The encode method must be implemented by subclasses\")\n",
        "\n",
        "\n",
        "class APIBaseEmbedding(BaseEmbedding):\n",
        "    baseUrl: str\n",
        "    apiKey: str\n",
        "\n",
        "    def __init__(self, name: str = None, baseUrl: str = None, apiKey: str = None):\n",
        "        super().__init__(name)\n",
        "        self.baseUrl = baseUrl\n",
        "        self.apiKey = apiKey"
      ],
      "metadata": {
        "id": "t1RC_auqFbgQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from typing import Optional, Union, List\n",
        "from fastembed import TextEmbedding\n",
        "from embeddings import BaseEmbedding\n",
        "\n",
        "class FastEmbedding(BaseEmbedding):\n",
        "    def __init__(\n",
        "            self,\n",
        "            # Multilingual model\n",
        "            name: str = 'BAAI/bge-m3',\n",
        "            max_length:int = 512\n",
        "        ):\n",
        "        super().__init__(name=name)\n",
        "\n",
        "        try:\n",
        "            self.embedding_model = TextEmbedding(\n",
        "                name=name,\n",
        "                max_length=max_length\n",
        "            )\n",
        "        except Exception as e:\n",
        "            raise ValueError(\n",
        "                f\"Fastembed failed to initialize. Error: {e}\"\n",
        "            ) from e\n",
        "\n",
        "    def encode(self, docs: List[str]):\n",
        "        try:\n",
        "            embeds = self.embedding_model.embed(docs)\n",
        "            embeddings: List[List[float]] = [e.tolist() for e in embeds]\n",
        "            return embeddings\n",
        "        except Exception as e:\n",
        "            raise ValueError(\n",
        "                f\"Failed to get embeddings. Error details: {e}\"\n",
        "            ) from e"
      ],
      "metadata": {
        "id": "vk6gcFQvExcF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from embeddings import APIBaseEmbedding\n",
        "import os\n",
        "import openai\n",
        "from typing import Any, List, Optional\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "class GoogleEmbedding(APIBaseEmbedding):\n",
        "    def __init__(\n",
        "        self,\n",
        "        name: str = \"textembedding-gecko@003\",\n",
        "        dimensions: int = 768,\n",
        "        token_limit: int = 8192,\n",
        "        baseUrl: str = None,\n",
        "        apiKey: str = None,\n",
        "        projectId: str = None,\n",
        "        location: str = None,\n",
        "    ):\n",
        "        super().__init__(name=name, baseUrl=baseUrl, apiKey=apiKey)\n",
        "        self.name = name\n",
        "\n",
        "        try:\n",
        "            from google.cloud import aiplatform\n",
        "            from vertexai.language_models import TextEmbeddingModel\n",
        "        except ImportError:\n",
        "            raise ImportError(\n",
        "                \"To use GoogleEmbedding, please install the Google Cloud and Vertex AI libraries \"\n",
        "                \"You can do this with the following command: \"\n",
        "                \"`pip install google-cloud-aiplatform vertexai-language-models`\"\n",
        "            )\n",
        "\n",
        "        projectId = projectId or os.getenv(\"GOOGLE_PROJECT_ID\")\n",
        "        location = location or os.getenv(\"GOOGLE_LOCATION\", \"us-central1\")\n",
        "        baseUrl = baseUrl or os.getenv(\"GOOGLE_BASE_URL\")\n",
        "\n",
        "        if projectId is None:\n",
        "            raise ValueError(\"Google Project ID cannot be null.\")\n",
        "\n",
        "        try:\n",
        "            aiplatform.init(\n",
        "                project=projectId, location=location, api_endpoint=baseUrl\n",
        "            )\n",
        "            self.client = TextEmbeddingModel.from_pretrained(self.name)\n",
        "        except Exception as err:\n",
        "            raise ValueError(\n",
        "                f\"Failed to initialize Google AI Platform client. Error: {err}\"\n",
        "            ) from err\n",
        "\n",
        "    def encode(self, docs: List[str]):\n",
        "        try:\n",
        "            embeddings = self.client.get_embeddings(docs)\n",
        "            return [embedding.values for embedding in embeddings]\n",
        "        except Exception as e:\n",
        "            raise ValueError(f\"Google AI Platform API call failed. Error: {e}\") from e\n",
        ""
      ],
      "metadata": {
        "id": "EN7AGX8jFutj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from typing import Optional, Union, List\n",
        "from mistralai.client import MistralClient\n",
        "from embeddings import APIBaseEmbedding\n",
        "\n",
        "class MistralEmbedding(APIBaseEmbedding):\n",
        "    def __init__(\n",
        "            self,\n",
        "            name: str = \"mistral-embed\",\n",
        "            apiKey: str = None,\n",
        "        ):\n",
        "        super().__init__(name=name, apiKey=apiKey)\n",
        "        self.apiKey = apiKey or os.getenv(\"MISTRAL_KEY\")\n",
        "\n",
        "        if not self.apiKey:\n",
        "            raise ValueError(\"The Mistral API key must not be 'None'.\")\n",
        "\n",
        "        try:\n",
        "            self.client = MistralClient(\n",
        "                api_key=self.apiKey\n",
        "            )\n",
        "        except Exception as e:\n",
        "            raise ValueError(\n",
        "                f\"Mistral API client failed to initialize. Error: {e}\"\n",
        "            ) from e\n",
        "\n",
        "    def encode(self, docs: List[str]):\n",
        "        try:\n",
        "            embeds = self.client.embeddings(\n",
        "                    input=docs,\n",
        "                    model=self.name,\n",
        "                )\n",
        "            embeddings = [embeds_obj.embedding for embeds_obj in embeds.data]\n",
        "            return embeddings\n",
        "        except Exception as e:\n",
        "            raise ValueError(\n",
        "                f\"Failed to get embeddings. Error details: {e}\"\n",
        "            ) from e"
      ],
      "metadata": {
        "id": "cQtzXK7ZF3Qy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from typing import Optional, Union, List\n",
        "from pydantic.v1 import BaseModel, Field, PrivateAttr\n",
        "from embeddings import APIBaseEmbedding\n",
        "import openai\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "class OpenAIEmbedding(APIBaseEmbedding):\n",
        "    def __init__(\n",
        "            self,\n",
        "            name: str = \"text-embedding-3-small\",\n",
        "            dimensions: int = 768,\n",
        "            token_limit: int = 8192,\n",
        "            baseUrl: str = None,\n",
        "            apiKey: str = None,\n",
        "            orgId: str = None,\n",
        "        ):\n",
        "        super().__init__(name=name, baseUrl=baseUrl, apiKey=apiKey)\n",
        "        self.dimensions = dimensions\n",
        "        self.apiKey = apiKey or os.getenv(\"OPENAI_API_KEY\")\n",
        "        self.orgId = orgId or os.getenv(\"OPENAI_ORG_ID\")\n",
        "        self.baseUrl = orgId or os.getenv(\"OPENAI_BASE_URL\")\n",
        "\n",
        "        if not self.apiKey:\n",
        "            raise ValueError(\"The OpenAI API key must not be 'None'.\")\n",
        "\n",
        "        try:\n",
        "            self.client = openai.Client(\n",
        "                base_url=self.baseUrl, api_key=self.apiKey, organization=self.orgId\n",
        "            )\n",
        "        except Exception as e:\n",
        "            raise ValueError(\n",
        "                f\"OpenAI API client failed to initialize. Error: {e}\"\n",
        "            ) from e\n",
        "\n",
        "    def encode(self, docs: List[str]):\n",
        "        try:\n",
        "            embeds = self.client.embeddings.create(\n",
        "                    input=docs,\n",
        "                    model=self.name,\n",
        "                    dimensions=self.dimensions,\n",
        "                )\n",
        "            embeddings = [embeds_obj.embedding for embeds_obj in embeds.data]\n",
        "            return embeddings\n",
        "        except Exception as e:\n",
        "            raise ValueError(\n",
        "                f\"Failed to get embeddings. Error details: {e}\"\n",
        "            ) from e"
      ],
      "metadata": {
        "id": "_-finw-lFyaS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic.v1 import BaseModel, Field, validator\n",
        "from embeddings import BaseEmbedding, EmbeddingConfig\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "class SentenceTransformerEmbedding(BaseEmbedding):\n",
        "    def __init__(self, config: EmbeddingConfig):\n",
        "        super().__init__(config.name)\n",
        "        self.config = config\n",
        "        self.embedding_model = SentenceTransformer(self.config.name)\n",
        "\n",
        "    def encode(self, text: str):\n",
        "        return self.embedding_model.encode(text)"
      ],
      "metadata": {
        "id": "0e_xL1YcF8Op"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "RAG"
      ],
      "metadata": {
        "id": "GeX3n0oEEadc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pymongo\n",
        "import google.generativeai as genai\n",
        "from IPython.display import Markdown\n",
        "import textwrap\n",
        "from embeddings import SentenceTransformerEmbedding, EmbeddingConfig\n",
        "\n",
        "class RAG():\n",
        "    def __init__(self,\n",
        "            mongodbUri: str,\n",
        "            dbName: str,\n",
        "            dbCollection: str,\n",
        "            llm,\n",
        "            embeddingName: str ='keepitreal/vietnamese-sbert',\n",
        "        ):\n",
        "        self.client = pymongo.MongoClient(mongodbUri)\n",
        "        self.db = self.client[dbName]\n",
        "        self.collection = self.db[dbCollection]\n",
        "        self.embedding_model = SentenceTransformerEmbedding(\n",
        "            EmbeddingConfig(name=embeddingName)\n",
        "        )\n",
        "        self.llm = llm\n",
        "\n",
        "    def get_embedding(self, text):\n",
        "        if not text.strip():\n",
        "            return []\n",
        "\n",
        "        embedding = self.embedding_model.encode(text)\n",
        "        return embedding.tolist()\n",
        "\n",
        "    def vector_search(\n",
        "            self,\n",
        "            user_query: str,\n",
        "            limit=4):\n",
        "        \"\"\"\n",
        "        Perform a vector search in the MongoDB collection based on the user query.\n",
        "\n",
        "        Args:\n",
        "        user_query (str): The user's query string.\n",
        "\n",
        "        Returns:\n",
        "        list: A list of matching documents.\n",
        "        \"\"\"\n",
        "\n",
        "        # Generate embedding for the user query\n",
        "        query_embedding = self.get_embedding(user_query)\n",
        "\n",
        "        if query_embedding is None:\n",
        "            return \"Invalid query or embedding generation failed.\"\n",
        "\n",
        "        # Define the vector search pipeline\n",
        "        vector_search_stage = {\n",
        "            \"$vectorSearch\": {\n",
        "                \"index\": \"vector_index\",\n",
        "                \"queryVector\": query_embedding,\n",
        "                \"path\": \"embedding\",\n",
        "                \"numCandidates\": 400,\n",
        "                \"limit\": limit,\n",
        "            }\n",
        "        }\n",
        "\n",
        "        unset_stage = {\n",
        "            \"$unset\": \"embedding\"\n",
        "        }\n",
        "\n",
        "        project_stage = {\n",
        "            \"$project\": {\n",
        "                \"_id\": 0,\n",
        "                \"title\": 1,\n",
        "                # \"product_specs\": 1,\n",
        "                \"color_options\": 1,\n",
        "                \"current_price\": 1,\n",
        "                \"product_promotion\": 1,\n",
        "                \"score\": {\n",
        "                    \"$meta\": \"vectorSearchScore\"\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "\n",
        "        pipeline = [vector_search_stage, unset_stage, project_stage]\n",
        "\n",
        "        # Execute the search\n",
        "        results = self.collection.aggregate(pipeline)\n",
        "\n",
        "        return list(results)\n",
        "\n",
        "    def enhance_prompt(self, query):\n",
        "        get_knowledge = self.vector_search(query, 10)\n",
        "        enhanced_prompt = \"\"\n",
        "        i = 0\n",
        "        for result in get_knowledge:\n",
        "            if result.get('current_price'):\n",
        "                i += 1\n",
        "                enhanced_prompt += f\"\\n {i}) Tên: {result.get('title')}\"\n",
        "\n",
        "                if result.get('current_price'):\n",
        "                    enhanced_prompt += f\", Giá: {result.get('current_price')}\"\n",
        "                else:\n",
        "                    # Mock up data\n",
        "                    # Retrieval model pricing from the internet.\n",
        "                    enhanced_prompt += f\", Giá: Liên hệ để trao đổi thêm!\"\n",
        "\n",
        "                if result.get('product_promotion'):\n",
        "                    enhanced_prompt += f\", Ưu đãi: {result.get('product_promotion')}\"\n",
        "        return enhanced_prompt\n",
        "\n",
        "    def generate_content(self, prompt):\n",
        "        return self.llm.generate_content(prompt)\n",
        "\n",
        "    def _to_markdown(text):\n",
        "        text = text.replace('•', '  *')\n",
        "        return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
      ],
      "metadata": {
        "id": "VKz5KVWtESvS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reflection"
      ],
      "metadata": {
        "id": "qHWUB2foGMhR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from reflection.core import Reflection"
      ],
      "metadata": {
        "id": "NDA5kBPJGN42"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Reflection():\n",
        "    def __init__(self, llm):\n",
        "        self.llm = llm\n",
        "\n",
        "    def _concat_and_format_texts(self, data):\n",
        "        concatenatedTexts = []\n",
        "        for entry in data:\n",
        "            role = entry.get('role', '')\n",
        "            all_texts = ' '.join(part['text'] for part in entry['parts'])\n",
        "            concatenatedTexts.append(f\"{role}: {all_texts} \\n\")\n",
        "        return ''.join(concatenatedTexts)\n",
        "\n",
        "\n",
        "    def __call__(self, chatHistory, lastItemsConsidereds=100):\n",
        "\n",
        "        if len(chatHistory) >= lastItemsConsidereds:\n",
        "            chatHistory = chatHistory[len(chatHistory) - lastItemsConsidereds:]\n",
        "\n",
        "        historyString = self._concat_and_format_texts(chatHistory)\n",
        "\n",
        "        higherLevelSummariesPrompt = \"\"\"Given a chat history and the latest user question which might reference context in the chat history, formulate a standalone question in Vietnamese which can be understood without the chat history. Do NOT answer the question, just reformulate it if needed and otherwise return it as is. {historyString}\n",
        "        \"\"\".format(historyString=historyString)\n",
        "\n",
        "        print(higherLevelSummariesPrompt)\n",
        "\n",
        "        completion = self.llm.chat.completions.create(\n",
        "            model=\"gpt-4o\",\n",
        "            messages=[\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": higherLevelSummariesPrompt\n",
        "                }\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        return completion.choices[0].message.content"
      ],
      "metadata": {
        "id": "pyBmIKzbGOiC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Semantic Router"
      ],
      "metadata": {
        "id": "WBGvZ4UWGlnT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from semantic_router.route import Route\n",
        "from semantic_router.router import SemanticRouter\n",
        "from semantic_router.samples import *"
      ],
      "metadata": {
        "id": "syNU_pQMGe6T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "class Route():\n",
        "    def __init__(\n",
        "        self,\n",
        "        name: str = None,\n",
        "        samples:List = []\n",
        "    ):\n",
        "\n",
        "        self.name = name\n",
        "        self.samples = samples"
      ],
      "metadata": {
        "id": "hdvJelnrGsJE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class SemanticRouter():\n",
        "    def __init__(self, embedding, routes):\n",
        "        self.routes = routes\n",
        "        self.embedding = embedding\n",
        "        self.routesEmbedding = {}\n",
        "\n",
        "        for route in self.routes:\n",
        "            self.routesEmbedding[\n",
        "                route.name\n",
        "            ] = self.embedding.encode(route.samples)\n",
        "\n",
        "    def get_routes(self):\n",
        "        return self.routes\n",
        "\n",
        "    def guide(self, query):\n",
        "        queryEmbedding = self.embedding.encode([query])\n",
        "        queryEmbedding = queryEmbedding / np.linalg.norm(queryEmbedding)\n",
        "        scores = []\n",
        "\n",
        "        # Calculate the cosine similarity of the query embedding with the sample embeddings of the router.\n",
        "\n",
        "        for route in self.routes:\n",
        "            routesEmbedding = self.routesEmbedding[route.name] / np.linalg.norm(self.routesEmbedding[route.name])\n",
        "            score = np.mean(np.dot(routesEmbedding, queryEmbedding.T).flatten())\n",
        "            scores.append((score, route.name))\n",
        "\n",
        "        scores.sort(reverse=True)\n",
        "        return scores[0]"
      ],
      "metadata": {
        "id": "kZ4Tvc6BGvPG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8COFV0SeGzmB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}